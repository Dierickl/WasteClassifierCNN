{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupe E - Projet de Deep Learning \n",
    "\n",
    "Luis Dierick, Tom Marchal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en place\n",
    "\n",
    "Pour réaliser ce projet, nous avons besoin de plusieurs librairies python. A savoir principalement : \n",
    "- PyTorch et Scikit Learn pour pouvoir créer notre CNN et utiliser des fonctions utiles en machine learning\n",
    "- Numpy pour manipuler et calculer certaines caractéristiques sur des tableaux\n",
    "- Matplotlib pour visualiser nos résultats\n",
    "\n",
    "Pour information, le modèle a été entrainé sur un GPU Intel d'où la présence du module `intel_extension_for_pytorch` qui permet d'utiliser l'accelération GPU et optimiser les calculs sur celle-ci.\n",
    "\n",
    "On definit également certaines variables qui resteront constantes durant l'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.v2 as T2\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler\n",
    "\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "\n",
    "device = 'xpu' if torch.xpu.is_available() else 'cpu' # Utilise la carte graphique, si GPU intel est disponible\n",
    "\n",
    "\n",
    "NB_CLASSES = 8\n",
    "CLASSES = ['battery', 'cardboard', 'glass', 'metal', 'organic', 'paper', 'plastic', 'textile']\n",
    "NB_EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "DTYPE = torch.float32\n",
    "LR = 0.001\n",
    "L1_REG = 0.01\n",
    "TRAIN_DATA = \"./waste-classification-challenge/train/train/\"\n",
    "TEST_DATA = \"./waste-classification-challenge/test/test/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données\n",
    "Au niveau des données, nous avons reçu initialement $\\approx$ 8000 images de déchets. Le set d'entrainement contient $\\approx$ 5500 images labbelées en 8 catégories (battery, cardboard, glass, metal, organic, paper, plastic, textile). Les $\\approx$ 2500 images restantes ne sont pas labbelées et servent à soumettre nos predictions pour la competition Kaggle.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T2.Compose(\n",
    "    [\n",
    "        T2.ToImage(),\n",
    "        T2.ToDtype(DTYPE),\n",
    "        T2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        T2.RandomHorizontalFlip(),\n",
    "        T2.RandomVerticalFlip(),\n",
    "        T2.RandomRotation(degrees=30),\n",
    "        T2.RandomChannelPermutation(),\n",
    "        T2.RandomResizedCrop(224, scale=(0.6, 1), antialias=True),\n",
    "        T2.ColorJitter(brightness=(0.5, 1.5), contrast=(0.5, 1.5), saturation=(0.5, 1.5)),\n",
    "        T2.GaussianBlur(kernel_size=(3, 9)),\n",
    "    ]\n",
    ").to(device)\n",
    "\n",
    "test_transform = T2.Compose(\n",
    "    [\n",
    "        T2.ToImage(),\n",
    "        T2.ToDtype(DTYPE),\n",
    "        T2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        T2.Resize(224, antialias=True),\n",
    "        T2.CenterCrop(224),\n",
    "    ]\n",
    ").to(device)\n",
    "\n",
    "dataset = ImageFolder(root=TRAIN_DATA)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant tout, observons la distribution des données en termes de categories afin de voir si certaines précoutions devrons être prises avant l'entrainement d'un modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHhCAYAAACIm3+PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABx+ElEQVR4nO3dd1gU1/s28HvpSBWliA3sYkOxYY+NIJZYY35GsTdsGBvGbmKLJdGgxtg1llgT0dhr7L13UWxAFARBpT7vH747X1bAsLpkYb0/17WX7szZ2WfY3dl7z5yZUYmIgIiIiMhAGem7ACIiIqLsxLBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDOVrXrl3h5uamMU2lUmHChAnZ/twHDx6ESqXCwYMHlWkNGjRA+fLls/25AeD+/ftQqVRYvnz5f/J89HEaNGiABg0a6LuMHCEiIgLt2rVDvnz5oFKp8OOPP2q9jK5du8La2lr3xWnx/O9ueyj3YtgxQMuXL4dKpVJuFhYWcHV1hY+PD+bOnYuXL19+8LKPHTuGCRMm4MWLF7or+D+wZs2aD9rg/hdycm1EHyIwMBC7du1CUFAQVq1ahc8//zzDdq9evcKECRM0flAYgilTpmDr1q36LgMAcO3aNUyYMAH379/Xdyl6ZaLvAij7TJo0Ce7u7khKSkJ4eDgOHjyIIUOGYPbs2fjzzz9RsWJFrZd57NgxTJw4EV27doW9vb3ui86C169fw8REu7fumjVrcOXKFQwZMiTLj6lXrx5ev34NMzMzLSvUTma1FS1aFK9fv4apqWm2Pj+Rru3fvx+tWrXCsGHD3tvu1atXmDhxIgAYVK/YlClT0K5dO3zxxRf6LgXXrl3DxIkT0aBBg0+6p4phx4D5+vqiatWqyv2goCDs378fzZs3R8uWLXH9+nVYWlrqscIPY2Fhka3Lf/PmDczMzGBkZJTtz/U+6l65T1V8fDysrKz0XQZ9gMjISL39GCLKCHdjfWIaNmyIsWPH4sGDB1i9erUy/dKlS+jatSuKFSsGCwsLuLi4oHv37nj+/LnSZsKECRg+fDgAwN3dXdlNpu4eXbZsGRo2bAgnJyeYm5vDw8MDCxYsyHJtW7duRfny5WFhYYHy5ctjy5YtGbZ7d8zOy5cvMWTIELi5ucHc3BxOTk5o0qQJzp07B+DtL8bt27fjwYMHSs3qXzjqcTnr1q3DmDFjULBgQeTJkwexsbEZjtlRO3v2LGrVqgVLS0u4u7tj4cKFGvPVuxLf7Tp+d5nvqy2zMTv79+9H3bp1YWVlBXt7e7Rq1QrXr1/XaDNhwgSoVCrcuXNH6YWzs7NDt27d8OrVq8xfhP/vyJEjaN++PYoUKQJzc3MULlwYgYGBeP36dbq2N27cQIcOHeDo6AhLS0uULl0a3377rUabx48fo0ePHnB1dYW5uTnc3d3Rr18/JCYmavy9Dh06hP79+8PJyQmFChVSHj9//nyUK1cO5ubmcHV1RUBAQLpdqbdv30bbtm3h4uICCwsLFCpUCB07dkRMTIzSZs+ePahTpw7s7e1hbW2N0qVLY/To0f/69wCA1atXo3r16siTJw/y5s2LevXqYffu3Zm2T0xMxLhx4+Dl5QU7OztYWVmhbt26OHDgQLq269atg5eXF2xsbGBra4sKFSrgp59+UuYnJSVh4sSJKFmyJCwsLJAvXz7UqVMHe/bs0VjOjRs30K5dOzg4OMDCwgJVq1bFn3/+qdEmq8vKyL1799C+fXs4ODggT548qFmzJrZv367MV7+OIoLg4GDlPZ2R+/fvw9HREQAwceJEpe274/EeP36ML774AtbW1nB0dMSwYcOQkpKi0SY1NRU//vgjypUrBwsLCzg7O6NPnz6Ijo7+13UCsr7tmTlzJmrVqoV8+fLB0tISXl5e2Lhxo0YblUqF+Ph4rFixQlmnrl27AgAePHiA/v37o3Tp0rC0tES+fPnQvn37dNsJXb3ey5cvR/v27QEAn332mVKPoe02zAr27HyCOnfujNGjR2P37t3o1asXgLdfAvfu3UO3bt3g4uKCq1evYtGiRbh69SpOnDgBlUqFNm3a4NatW1i7di3mzJmD/PnzA4CywVqwYAHKlSuHli1bwsTEBNu2bUP//v2RmpqKgICA99a0e/dutG3bFh4eHpg6dSqeP3+Obt26aXzhZaZv377YuHEjBgwYAA8PDzx//hx///03rl+/jipVquDbb79FTEwMHj16hDlz5gBAuoGPkydPhpmZGYYNG4aEhIT37rqKjo5Gs2bN0KFDB3z11Vf4/fff0a9fP5iZmaF79+7/Wm9aWaktrb1798LX1xfFihXDhAkT8Pr1a8ybNw+1a9fGuXPn0nVTd+jQAe7u7pg6dSrOnTuHxYsXw8nJCdOnT39vXRs2bMCrV6/Qr18/5MuXD6dOncK8efPw6NEjbNiwQWl36dIl1K1bF6ampujduzfc3Nxw9+5dbNu2Dd9//z0A4MmTJ6hevTpevHiB3r17o0yZMnj8+DE2btyIV69eafyt+/fvD0dHR4wbNw7x8fEA3ga3iRMnonHjxujXrx9u3ryJBQsW4PTp0zh69ChMTU2RmJgIHx8fJCQkYODAgXBxccHjx48REhKCFy9ewM7ODlevXkXz5s1RsWJFTJo0Cebm5rhz5w6OHj36r6/TxIkTMWHCBNSqVQuTJk2CmZkZTp48if3796Np06YZPiY2NhaLFy/GV199hV69euHly5dYsmQJfHx8cOrUKXh6egJ4+9n76quv0KhRI+V1uX79Oo4ePYrBgwcrf4OpU6eiZ8+eqF69OmJjY3HmzBmcO3cOTZo0AQBcvXoVtWvXRsGCBTFq1ChYWVnh999/xxdffIFNmzahdevWWV5WRiIiIlCrVi28evUKgwYNQr58+bBixQq0bNkSGzduROvWrVGvXj2sWrUKnTt3RpMmTdClS5dMl+fo6IgFCxagX79+aN26Ndq0aQMAGrvXU1JS4OPjgxo1amDmzJnYu3cvZs2aheLFi6Nfv35Kuz59+mD58uXo1q0bBg0ahNDQUPz88884f/688h7JjDbbnp9++gktW7ZEp06dkJiYiHXr1qF9+/YICQmBn58fAGDVqlXK37Z3794AgOLFiwMATp8+jWPHjqFjx44oVKgQ7t+/jwULFqBBgwa4du0a8uTJo9PXu169ehg0aBDmzp2L0aNHo2zZsgCg/PtJETI4y5YtEwBy+vTpTNvY2dlJ5cqVlfuvXr1K12bt2rUCQA4fPqxM++GHHwSAhIaGpmuf0TJ8fHykWLFi/1qzp6enFChQQF68eKFM2717twCQokWLarQFIOPHj9dYl4CAgPcu38/PL91yREQOHDggAKRYsWLp6lfPO3DggDKtfv36AkBmzZqlTEtISBBPT09xcnKSxMREEfnfa/Du3ymjZWZWW2hoqACQZcuWKdPUz/P8+XNl2sWLF8XIyEi6dOmiTBs/frwAkO7du2sss3Xr1pIvX750z/WujF7LqVOnikqlkgcPHijT6tWrJzY2NhrTRERSU1OV/3fp0kWMjIwyfD+q26n/XnXq1JHk5GRlfmRkpJiZmUnTpk0lJSVFmf7zzz8LAFm6dKmIiJw/f14AyIYNGzJdpzlz5ggA+eeff/5t9TXcvn1bjIyMpHXr1ho1vLue9evXl/r16yv3k5OTJSEhQaN9dHS0ODs7a7wugwcPFltbW431flelSpXEz8/vvXU2atRIKlSoIG/evNGor1atWlKyZEmtlpWRIUOGCAA5cuSIMu3ly5fi7u4ubm5uGn8bAP/6mRQR+eeff9J9ntX8/f0FgEyaNEljeuXKlcXLy0u5f+TIEQEgv/32m0a7nTt3Zjj9Xdpse979XCQmJkr58uWlYcOGGtOtrKzE398/3XNl9Lk6fvy4AJCVK1cq03T5em/YsCHdNudTxN1Ynyhra2uNo7LSjt158+YNnj17hpo1awKAsjvo36RdRkxMDJ49e4b69evj3r17GrsS3vX06VNcuHAB/v7+sLOzU6Y3adIEHh4e//q89vb2OHnyJJ48eZKlOjPi7++f5fFLJiYm6NOnj3LfzMwMffr0QWRkJM6ePfvBNfwb9d+pa9eucHBwUKZXrFgRTZo0wY4dO9I9pm/fvhr369ati+fPnyM2Nva9z5X2bxEfH49nz56hVq1aEBGcP38eAPDPP//g8OHD6N69O4oUKaLxePWui9TUVGzduhUtWrTQGD/2bju1Xr16wdjYWLm/d+9eJCYmYsiQITAyMtJoZ2trq+xCUb9vdu3aleluOvUYkj/++AOpqanvXf+0tm7ditTUVIwbN06jhozqT8vY2FjptUpNTUVUVBSSk5NRtWpVjc+Uvb094uPj37sbyd7eHlevXsXt27cznB8VFYX9+/ejQ4cOePnyJZ49e4Znz57h+fPn8PHxwe3bt/H48eMsLSszO3bsQPXq1VGnTh1lmrW1NXr37o379+/j2rVrWi0vqzJ6D9+7d0+5v2HDBtjZ2aFJkybKej979gxeXl6wtrbOcLehmrbbnrSfi+joaMTExKBu3boftI1MSkrC8+fPUaJECdjb26d7T+jq9aa3GHY+UXFxcbCxsVHuR0VFYfDgwXB2doalpSUcHR3h7u4OAO8NKmkdPXoUjRs3VsaSODo6KuMh3reMBw8eAABKliyZbl7p0qX/9XlnzJiBK1euoHDhwqhevTomTJigsTHMCvW6ZoWrq2u6gbOlSpUCgGw9vFP9d8rob1K2bFk8e/ZM2fWj9m4IyZs3LwD861iGsLAwJVSpx0rUr18fwP9eS/Xf+H3nHfrnn38QGxub5XMTvfs6ZLbOZmZmKFasmDLf3d0dQ4cOxeLFi5E/f374+PggODhY43335Zdfonbt2ujZsyecnZ3RsWNH/P777/8afO7evQsjI6MsBe93rVixAhUrVlTGXTg6OmL79u0adfXv3x+lSpWCr68vChUqhO7du2Pnzp0ay5k0aRJevHiBUqVKoUKFChg+fDguXbqkzL9z5w5EBGPHjoWjo6PGbfz48QDeDhrOyrIy8+DBg0zfe+r5umZhYaHsJlfLmzevxvv39u3biImJgZOTU7p1j4uLU9Y7I9pue0JCQlCzZk1YWFjAwcFB2RWX1W3k69evMW7cOBQuXBjm5ubInz8/HB0d8eLFC41l6PL1prc4ZucT9OjRI8TExKBEiRLKtA4dOuDYsWMYPnw4PD09YW1tjdTUVHz++edZ+hV89+5dNGrUCGXKlMHs2bNRuHBhmJmZYceOHZgzZ45Wv6S11aFDB9StWxdbtmzB7t278cMPP2D69OnYvHkzfH19s7QMXR+Vltkv/ncHVma3tL0kaYlIpo9JSUlBkyZNEBUVhZEjR6JMmTKwsrLC48eP0bVr12x9LT/mdZg1axa6du2KP/74A7t378agQYMwdepUnDhxAoUKFYKlpSUOHz6MAwcOYPv27di5cyfWr1+Phg0bYvfu3Zn+rT7U6tWr0bVrV3zxxRcYPnw4nJycYGxsjKlTp+Lu3btKOycnJ1y4cAG7du3CX3/9hb/++gvLli1Dly5dsGLFCgBvT4Nw9+5dZd0WL16MOXPmYOHChejZs6fymgwbNgw+Pj4Z1qP+vP/bsnKSrLwmqampcHJywm+//Zbh/HfD0oc6cuQIWrZsiXr16mH+/PkoUKAATE1NsWzZMqxZsyZLyxg4cCCWLVuGIUOGwNvbG3Z2dlCpVOjYsaPG50qXrze9xbDzCVq1ahUAKB+S6Oho7Nu3DxMnTsS4ceOUdhl1oWb2Jb5t2zYkJCTgzz//1OhNeF8XslrRokUzfb6bN2/+6+MBoECBAujfvz/69++PyMhIVKlSBd9//70Sdt63u0FbT548SXdY9K1btwBAGSCs7kF594ihjH79ZrU29d8po7/JjRs3kD9/fp0cqn358mXcunULK1as0Bhg+u5ulmLFigEArly5kumyHB0dYWtr+94275N2ndXPB7w90ik0NBSNGzfWaF+hQgVUqFABY8aMwbFjx1C7dm0sXLgQ3333HQDAyMgIjRo1QqNGjTB79mxMmTIF3377LQ4cOJBuWWrFixdHamoqrl27pgwqzoqNGzeiWLFi2Lx5s8ZrrP7lnZaZmRlatGiBFi1aIDU1Ff3798cvv/yCsWPHKl9aDg4O6NatG7p164a4uDjUq1cPEyZMQM+ePZW/jampaabrkdb7lpWZokWLZvreU8/Xli4+l8WLF8fevXtRu3ZtrcOyNtueTZs2wcLCArt27YK5ubkyfdmyZekem9l6bdy4Ef7+/pg1a5Yy7c2bNxmepFVXr7cut325GXdjfWL279+PyZMnw93dHZ06dQLwv19P7/7az+isvuov03c/nBktIyYmJsMNwbsKFCgAT09PrFixIt1hwv82DiAlJSVdF7KTkxNcXV2RkJCgUXdWu5r/TXJyMn755RflfmJiIn755Rc4OjrCy8sLwP+Ovjh8+LBGrYsWLUq3vKzWlvbvlPbvf+XKFezevRvNmjX70FXSkNFrKSIah0IDb4NMvXr1sHTpUoSFhWnMUz/WyMgIX3zxBbZt24YzZ86ke6739TABQOPGjWFmZoa5c+dqtF2yZAliYmKUI2BiY2ORnJys8dgKFSrAyMhIeR9ERUWlW746vKR9r7zriy++gJGRESZNmpSuV+t99Wf0dzx58iSOHz+u0S7t6R2At38z9RFJ6rrebWNtbY0SJUoo852cnNCgQQP88ssvePr0abpa/vnnn0yf791lZaZZs2Y4deqURv3x8fFYtGgR3NzcPmg3n/roo485I3uHDh2QkpKCyZMnp5uXnJz83mVrs+0xNjaGSqXS6J29f/9+hmdKtrKyyvB5jY2N071n5s2bl67HV5evd2bb7E8Ne3YM2F9//YUbN24gOTkZERER2L9/P/bs2YOiRYvizz//VE5YZ2tri3r16mHGjBlISkpCwYIFsXv3boSGhqZbpvrL/Ntvv0XHjh1hamqKFi1aoGnTpsqv0z59+iAuLg6//vornJycMvwwvmvq1Knw8/NDnTp10L17d0RFRWHevHkoV64c4uLiMn3cy5cvUahQIbRr1w6VKlWCtbU19u7di9OnT2v8evLy8sL69esxdOhQVKtWDdbW1mjRooW2f1IAb8fsTJ8+Hffv30epUqWwfv16XLhwAYsWLVIOcS1Xrhxq1qyJoKAgREVFwcHBAevWrUv3haxtbT/88AN8fX3h7e2NHj16KIee29nZ6ex6YWXKlEHx4sUxbNgwPH78GLa2tti0aVOG43zmzp2LOnXqoEqVKujduzfc3d1x//59bN++HRcuXADw9myyu3fvRv369dG7d2+ULVsWT58+xYYNG/D333+/9+Rzjo6OCAoKwsSJE/H555+jZcuWuHnzJubPn49q1arh66+/BvA2xA8YMADt27dHqVKlkJycjFWrVsHY2Bht27YF8HYcxOHDh+Hn54eiRYsiMjIS8+fPR6FChTQG3b6rRIkS+PbbbzF58mTUrVsXbdq0gbm5OU6fPg1XV1dMnTo1w8c1b94cmzdvRuvWreHn54fQ0FAsXLgQHh4eGu/pnj17IioqCg0bNkShQoXw4MEDzJs3D56ensp4GA8PDzRo0ABeXl5wcHDAmTNnlNMtqAUHB6NOnTqoUKECevXqhWLFiiEiIgLHjx/Ho0ePcPHixSwvKyOjRo3C2rVr4evri0GDBsHBwQErVqxAaGgoNm3alG7wdlZYWlrCw8MD69evR6lSpeDg4IDy5ctrdf25+vXro0+fPpg6dSouXLiApk2bwtTUFLdv38aGDRvw008/oV27dpk+PqvbHj8/P8yePRuff/45/u///g+RkZEIDg5GiRIl0o158vLywt69ezF79my4urrC3d0dNWrUQPPmzbFq1SrY2dnBw8MDx48fx969e5EvXz6Nx+vy9fb09ISxsTGmT5+OmJgYmJubK+dD+6To4xAwyl7qw3jVNzMzM3FxcZEmTZrITz/9JLGxseke8+jRI2ndurXY29uLnZ2dtG/fXp48eZLhYaGTJ0+WggULipGRkcbh1X/++adUrFhRLCwsxM3NTaZPny5Lly7N9FD1d23atEnKli0r5ubm4uHhIZs3bxZ/f//3HnqekJAgw4cPl0qVKomNjY1YWVlJpUqVZP78+RqPiYuLk//7v/8Te3t7jUNK1YeCZ3TIcmaHnpcrV07OnDkj3t7eYmFhIUWLFpWff/453ePv3r0rjRs3FnNzc3F2dpbRo0fLnj170i0zs9oyOvRcRGTv3r1Su3ZtsbS0FFtbW2nRooVcu3ZNo4360PN3D7PO7JD4d127dk0aN24s1tbWkj9/funVq5dcvHgxw3quXLmivHcsLCykdOnSMnbsWI02Dx48kC5duoijo6OYm5tLsWLFJCAgQDk0+99Ol/Dzzz9LmTJlxNTUVJydnaVfv34SHR2tzL937550795dihcvLhYWFuLg4CCfffaZ7N27V2mzb98+adWqlbi6uoqZmZm4urrKV199Jbdu3Xrv30Jt6dKlUrlyZTE3N5e8efNK/fr1Zc+ePcr8dw89T01NlSlTpkjRokXF3NxcKleuLCEhIene0xs3bpSmTZuKk5OTmJmZSZEiRaRPnz7y9OlTpc13330n1atXF3t7e7G0tJQyZcrI999/r5zqQO3u3bvSpUsXcXFxEVNTUylYsKA0b95cNm7cqPWyMnL37l1p166d8lpXr15dQkJC0rVDFg89FxE5duyYeHl5iZmZmcZn29/fX6ysrNK1V7+337Vo0SLx8vISS0tLsbGxkQoVKsiIESPkyZMn/1pDVrc9S5YskZIlS4q5ubmUKVNGli1blmE9N27ckHr16omlpaUAUA5Dj46Olm7dukn+/PnF2tpafHx85MaNG1K0aFGNQ9V1+XqLiPz6669SrFgxMTY2/mQPQ1eJ/Es/MhEREVEuxjE7REREZNAYdoiIiMigMewQERGRQWPYISIiIoPGsENEREQGjWGHiIiIDBpPKoi311Z58uQJbGxseGptIiKiXEJE8PLlS7i6ur73xJYMO3h7raPChQvruwwiIiL6AA8fPkShQoUync+wA8DGxgbA2z+Wra2tnqshIiKirIiNjUXhwoWV7/HMMOzgf1eFtbW1ZdghIiLKZf5tCAoHKBMREZFBY9ghIiIig8awQ0RERAaNYYeIiIgMGsMOERERGTSGHSIiIjJoDDtERERk0Bh2iIiIyKAx7BAREZFBY9ghIiIig6bXsOPm5gaVSpXuFhAQAAB48+YNAgICkC9fPlhbW6Nt27aIiIjQWEZYWBj8/PyQJ08eODk5Yfjw4UhOTtbH6hAREVEOpNewc/r0aTx9+lS57dmzBwDQvn17AEBgYCC2bduGDRs24NChQ3jy5AnatGmjPD4lJQV+fn5ITEzEsWPHsGLFCixfvhzjxo3Ty/oQERFRzqMSEdF3EWpDhgxBSEgIbt++jdjYWDg6OmLNmjVo164dAODGjRsoW7Ysjh8/jpo1a+Kvv/5C8+bN8eTJEzg7OwMAFi5ciJEjR+Kff/6BmZlZlp43NjYWdnZ2iImJ4YVAiYiIcomsfn/nmDE7iYmJWL16Nbp37w6VSoWzZ88iKSkJjRs3VtqUKVMGRYoUwfHjxwEAx48fR4UKFZSgAwA+Pj6IjY3F1atXM32uhIQExMbGatyIiIjIMJnouwC1rVu34sWLF+jatSsAIDw8HGZmZrC3t9do5+zsjPDwcKVN2qCjnq+el5mpU6di4sSJuiue4DZqu75L+CD3p/lp1Z7rmbNps565dR2BT2M9+Z7N2KeynrqWY3p2lixZAl9fX7i6umb7cwUFBSEmJka5PXz4MNufk4iIiPQjR/TsPHjwAHv37sXmzZuVaS4uLkhMTMSLFy80enciIiLg4uKitDl16pTGstRHa6nbZMTc3Bzm5uY6XAMiIiLKqXJEz86yZcvg5OQEP7//dXN5eXnB1NQU+/btU6bdvHkTYWFh8Pb2BgB4e3vj8uXLiIyMVNrs2bMHtra28PDw+O9WgIiIiHIsvffspKamYtmyZfD394eJyf/KsbOzQ48ePTB06FA4ODjA1tYWAwcOhLe3N2rWrAkAaNq0KTw8PNC5c2fMmDED4eHhGDNmDAICAthzQ0RERAByQNjZu3cvwsLC0L1793Tz5syZAyMjI7Rt2xYJCQnw8fHB/PnzlfnGxsYICQlBv3794O3tDSsrK/j7+2PSpEn/5SoQERFRDqb3sNO0aVNkdqofCwsLBAcHIzg4ONPHFy1aFDt27Miu8oiIiCiXyxFjdoiIiIiyC8MOERERGTSGHSIiIjJoDDtERERk0Bh2iIiIyKAx7BAREZFBY9ghIiIig8awQ0RERAaNYYeIiIgMGsMOERERGTSGHSIiIjJoDDtERERk0Bh2iIiIyKDp/arnhs5t1HZ9l/BB7k/z03cJREREOsGeHSIiIjJoDDtERERk0Bh2iIiIyKAx7BAREZFBY9ghIiIig8awQ0RERAaNYYeIiIgMGsMOERERGTSGHSIiIjJoDDtERERk0Bh2iIiIyKAx7BAREZFBY9ghIiIig8awQ0RERAaNYYeIiIgMGsMOERERGTSGHSIiIjJoDDtERERk0Bh2iIiIyKAx7BAREZFBY9ghIiIig8awQ0RERAaNYYeIiIgMGsMOERERGTSGHSIiIjJoDDtERERk0PQedh4/foyvv/4a+fLlg6WlJSpUqIAzZ84o80UE48aNQ4ECBWBpaYnGjRvj9u3bGsuIiopCp06dYGtrC3t7e/To0QNxcXH/9aoQERFRDqTXsBMdHY3atWvD1NQUf/31F65du4ZZs2Yhb968SpsZM2Zg7ty5WLhwIU6ePAkrKyv4+PjgzZs3SptOnTrh6tWr2LNnD0JCQnD48GH07t1bH6tEREREOYyJPp98+vTpKFy4MJYtW6ZMc3d3V/4vIvjxxx8xZswYtGrVCgCwcuVKODs7Y+vWrejYsSOuX7+OnTt34vTp06hatSoAYN68eWjWrBlmzpwJV1fXdM+bkJCAhIQE5X5sbGx2rSIRERHpmV57dv78809UrVoV7du3h5OTEypXroxff/1VmR8aGorw8HA0btxYmWZnZ4caNWrg+PHjAIDjx4/D3t5eCToA0LhxYxgZGeHkyZMZPu/UqVNhZ2en3AoXLpxNa0hERET6ptewc+/ePSxYsAAlS5bErl270K9fPwwaNAgrVqwAAISHhwMAnJ2dNR7n7OyszAsPD4eTk5PGfBMTEzg4OCht3hUUFISYmBjl9vDhQ12vGhEREeUQet2NlZqaiqpVq2LKlCkAgMqVK+PKlStYuHAh/P39s+15zc3NYW5unm3LJyIiopxDrz07BQoUgIeHh8a0smXLIiwsDADg4uICAIiIiNBoExERocxzcXFBZGSkxvzk5GRERUUpbYiIiOjTpdewU7t2bdy8eVNj2q1bt1C0aFEAbwcru7i4YN++fcr82NhYnDx5Et7e3gAAb29vvHjxAmfPnlXa7N+/H6mpqahRo8Z/sBZERESUk+l1N1ZgYCBq1aqFKVOmoEOHDjh16hQWLVqERYsWAQBUKhWGDBmC7777DiVLloS7uzvGjh0LV1dXfPHFFwDe9gR9/vnn6NWrFxYuXIikpCQMGDAAHTt2zPBILCIiIvq06DXsVKtWDVu2bEFQUBAmTZoEd3d3/Pjjj+jUqZPSZsSIEYiPj0fv3r3x4sUL1KlTBzt37oSFhYXS5rfffsOAAQPQqFEjGBkZoW3btpg7d64+VomIiIhyGL2GHQBo3rw5mjdvnul8lUqFSZMmYdKkSZm2cXBwwJo1a7KjPCIiIsrl9H65CCIiIqLsxLBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoH102ElJScGFCxcQHR2t9WMnTJgAlUqlcStTpowy/82bNwgICEC+fPlgbW2Ntm3bIiIiQmMZYWFh8PPzQ548eeDk5IThw4cjOTn5Y1eLiIiIDITWYWfIkCFYsmQJgLdBp379+qhSpQoKFy6MgwcPal1AuXLl8PTpU+X2999/K/MCAwOxbds2bNiwAYcOHcKTJ0/Qpk0bZX5KSgr8/PyQmJiIY8eOYcWKFVi+fDnGjRundR1ERERkmLQOOxs3bkSlSpUAANu2bUNoaChu3LiBwMBAfPvtt1oXYGJiAhcXF+WWP39+AEBMTAyWLFmC2bNno2HDhvDy8sKyZctw7NgxnDhxAgCwe/duXLt2DatXr4anpyd8fX0xefJkBAcHIzExUetaiIiIyPBoHXaePXsGFxcXAMCOHTvQvn17lCpVCt27d8fly5e1LuD27dtwdXVFsWLF0KlTJ4SFhQEAzp49i6SkJDRu3FhpW6ZMGRQpUgTHjx8HABw/fhwVKlSAs7Oz0sbHxwexsbG4evVqps+ZkJCA2NhYjRsREREZJq3DjrOzM65du4aUlBTs3LkTTZo0AQC8evUKxsbGWi2rRo0aWL58OXbu3IkFCxYgNDQUdevWxcuXLxEeHg4zMzPY29une/7w8HAAQHh4uEbQUc9Xz8vM1KlTYWdnp9wKFy6sVd1ERESUe5ho+4Bu3bqhQ4cOKFCgAFQqldLzcvLkSY3BxVnh6+ur/L9ixYqoUaMGihYtit9//x2WlpbalpZlQUFBGDp0qHI/NjaWgYeIiMhAaR12JkyYgPLly+Phw4do3749zM3NAQDGxsYYNWrURxVjb2+PUqVK4c6dO2jSpAkSExPx4sULjd6diIgIZTeai4sLTp06pbEM9dFa6jYZMTc3V+omIiIiw/ZBh563a9cOgYGBymBiAPD390erVq0+qpi4uDjcvXsXBQoUgJeXF0xNTbFv3z5l/s2bNxEWFgZvb28AgLe3Ny5fvozIyEilzZ49e2BrawsPD4+PqoWIiIgMg9ZhJyUlBZMnT0bBggVhbW2Ne/fuAQDGjh2rHJKeVcOGDcOhQ4dw//59HDt2DK1bt4axsTG++uor2NnZoUePHhg6dCgOHDiAs2fPolu3bvD29kbNmjUBAE2bNoWHhwc6d+6MixcvYteuXRgzZgwCAgLYc0NEREQAPiDsfP/991i+fDlmzJgBMzMzZXr58uWxePFirZb16NEjfPXVVyhdujQ6dOiAfPny4cSJE3B0dAQAzJkzB82bN0fbtm1Rr149uLi4YPPmzcrjjY2NERISAmNjY3h7e+Prr79Gly5dMGnSJG1Xi4iIiAyU1mN2Vq5ciUWLFqFRo0bo27evMr1SpUq4ceOGVstat27de+dbWFggODgYwcHBmbYpWrQoduzYodXzEhER0adD656dx48fo0SJEummp6amIikpSSdFEREREemK1mHHw8MDR44cSTd948aNqFy5sk6KIiIiItIVrXdjjRs3Dv7+/nj8+DFSU1OxefNm3Lx5EytXrkRISEh21EhERET0wbTu2WnVqhW2bduGvXv3wsrKCuPGjcP169exbds25WzKRERERDmF1j07AFC3bl3s2bNH17UQERER6ZzWPTunT5/GyZMn000/efIkzpw5o5OiiIiIiHRF67ATEBCAhw8fppv++PFjBAQE6KQoIiIiIl3ROuxcu3YNVapUSTe9cuXKuHbtmk6KIiIiItIVrcOOubm5crHNtJ4+fQoTkw8aAkRERESUbbQOO02bNkVQUBBiYmKUaS9evMDo0aN5NBYRERHlOFp3xcycORP16tVD0aJFlZMIXrhwAc7Ozli1apXOCyQiIiL6GFqHnYIFC+LSpUv47bffcPHiRVhaWqJbt2746quvYGpqmh01EhEREX2wDxpkY2Vlhd69e+u6FiIiIiKd+6Cwc/v2bRw4cACRkZFITU3VmDdu3DidFEZERESkC1qHnV9//RX9+vVD/vz54eLiApVKpcxTqVQMO0RERJSjaB12vvvuO3z//fcYOXJkdtRDREREpFNaH3oeHR2N9u3bZ0ctRERERDqnddhp3749du/enR21EBEREemc1ruxSpQogbFjx+LEiROoUKFCusPNBw0apLPiiIiIiD6W1mFn0aJFsLa2xqFDh3Do0CGNeSqVimGHiIiIchStw05oaGh21EFERESULbQes0NERESUm3zQSQUfPXqEP//8E2FhYUhMTNSYN3v2bJ0URkRERKQLWoedffv2oWXLlihWrBhu3LiB8uXL4/79+xARVKlSJTtqJCIiIvpgWu/GCgoKwrBhw3D58mVYWFhg06ZNePjwIerXr8/z7xAREVGOo3XYuX79Orp06QIAMDExwevXr2FtbY1JkyZh+vTpOi+QiIiI6GNoHXasrKyUcToFChTA3bt3lXnPnj3TXWVEREREOqD1mJ2aNWvi77//RtmyZdGsWTN88803uHz5MjZv3oyaNWtmR41EREREH0zrsDN79mzExcUBACZOnIi4uDisX78eJUuW5JFYRERElONoHXaKFSum/N/KygoLFy7UaUFEREREuqT1mJ1ixYrh+fPn6aa/ePFCIwgRERER5QRah5379+8jJSUl3fSEhAQ8fvxYJ0URERER6UqWd2P9+eefyv937doFOzs75X5KSgr27dsHNzc3nRZHRERE9LGyHHa++OILAG+vbO7v768xz9TUFG5ubpg1a5ZOiyMiIiL6WFkOO6mpqQAAd3d3nD59Gvnz58+2ooiIiIh0ReujsUJDQ9NNe/HiBezt7XVRDxEREZFOaT1Aefr06Vi/fr1yv3379nBwcEDBggVx8eJFnRZHRERE9LG0DjsLFy5E4cKFAQB79uzB3r17sXPnTvj6+mL48OE6L5CIiIjoY2i9Gys8PFwJOyEhIejQoQOaNm0KNzc31KhRQ+cFEhEREX0MrXt28ubNi4cPHwIAdu7cicaNGwMARCTD8+9k1bRp06BSqTBkyBBl2ps3bxAQEIB8+fLB2toabdu2RUREhMbjwsLC4Ofnhzx58sDJyQnDhw9HcnLyB9dBREREhkXrsNOmTRv83//9H5o0aYLnz5/D19cXAHD+/HmUKFHig4o4ffo0fvnlF1SsWFFjemBgILZt24YNGzbg0KFDePLkCdq0aaPMT0lJgZ+fHxITE3Hs2DGsWLECy5cvx7hx4z6oDiIiIjI8WoedOXPmYMCAAfDw8MCePXtgbW0NAHj69Cn69++vdQFxcXHo1KkTfv31V+TNm1eZHhMTgyVLlmD27Nlo2LAhvLy8sGzZMhw7dgwnTpwAAOzevRvXrl3D6tWr4enpCV9fX0yePBnBwcFITEzUuhYiIiIyPFqHHVNTUwwbNgw//fQTKleurEwPDAxEz549tS4gICAAfn5+yu4wtbNnzyIpKUljepkyZVCkSBEcP34cAHD8+HFUqFABzs7OShsfHx/Exsbi6tWrmT5nQkICYmNjNW5ERERkmLQeoAwAt2/fxoEDBxAZGamcbFBNm11I69atw7lz53D69Ol088LDw2FmZpbu/D3Ozs4IDw9X2qQNOur56nmZmTp1KiZOnJjlOomIiCj30jrs/Prrr+jXrx/y588PFxcXqFQqZZ5Kpcpy2Hn48CEGDx6MPXv2wMLCQtsyPkpQUBCGDh2q3I+NjVWOMCMiIiLDonXY+e677/D9999j5MiRH/XEZ8+eRWRkJKpUqaJMS0lJweHDh/Hzzz9j165dSExMTHd25oiICLi4uAAAXFxccOrUKY3lqo/WUrfJiLm5OczNzT+qfiIiIsodtB6zEx0djfbt23/0Ezdq1AiXL1/GhQsXlFvVqlXRqVMn5f+mpqbYt2+f8pibN28iLCwM3t7eAABvb29cvnwZkZGRSps9e/bA1tYWHh4eH10jERER5X5a9+y0b98eu3fvRt++fT/qiW1sbFC+fHmNaVZWVsiXL58yvUePHhg6dCgcHBxga2uLgQMHwtvbGzVr1gQANG3aFB4eHujcuTNmzJiB8PBwjBkzBgEBAey5ISIiIgAfEHZKlCiBsWPH4sSJE6hQoQJMTU015g8aNEhnxc2ZMwdGRkZo27YtEhIS4OPjg/nz5yvzjY2NERISgn79+sHb2xtWVlbw9/fHpEmTdFYDERER5W5ah51FixbB2toahw4dwqFDhzTmqVSqjwo7Bw8e1LhvYWGB4OBgBAcHZ/qYokWLYseOHR/8nERERGTYtA47oaGh2VEHERERUbbQeoAyERERUW6SpZ6doUOHYvLkybCystI4P01GZs+erZPCiIiIiHQhS2Hn/PnzSEpKUv6fmbQnGCQiIiLKCbIUdg4cOJDh/4mIiIhyOo7ZISIiIoPGsENEREQGjWGHiIiIDBrDDhERERm0LIWdKlWqIDo6GgAwadIkvHr1KluLIiIiItKVLIWd69evIz4+HgAwceJExMXFZWtRRERERLqSpUPPPT090a1bN9SpUwcigpkzZ8La2jrDtuPGjdNpgUREREQfI0thZ/ny5Rg/fjxCQkKgUqnw119/wcQk/UNVKhXDDhEREeUoWQo7pUuXxrp16wAARkZG2LdvH5ycnLK1MCIiIiJd0Pqq56mpqdlRBxEREVG20DrsAMDdu3fx448/4vr16wAADw8PDB48GMWLF9dpcUREREQfS+vz7OzatQseHh44deoUKlasiIoVK+LkyZMoV64c9uzZkx01EhEREX0wrXt2Ro0ahcDAQEybNi3d9JEjR6JJkyY6K46IiIjoY2nds3P9+nX06NEj3fTu3bvj2rVrOimKiIiISFe0DjuOjo64cOFCuukXLlzgEVpERESU42i9G6tXr17o3bs37t27h1q1agEAjh49iunTp2Po0KE6L5CIiIjoY2gddsaOHQsbGxvMmjULQUFBAABXV1dMmDABgwYN0nmBRERERB9D67CjUqkQGBiIwMBAvHz5EgBgY2Oj88KIiIiIdOGDzrOjxpBDREREOZ3WA5SJiIiIchOGHSIiIjJoDDtERERk0LQKO0lJSWjUqBFu376dXfUQERER6ZRWYcfU1BSXLl3KrlqIiIiIdE7r3Vhff/01lixZkh21EBEREemc1oeeJycnY+nSpdi7dy+8vLxgZWWlMX/27Nk6K46IiIjoY2kddq5cuYIqVaoAAG7duqUxT6VS6aYqIiIiIh3ROuwcOHAgO+ogIiIiyhYffOj5nTt3sGvXLrx+/RoAICI6K4qIiIhIV7QOO8+fP0ejRo1QqlQpNGvWDE+fPgUA9OjRA998843OCyQiIiL6GFqHncDAQJiamiIsLAx58uRRpn/55ZfYuXOnTosjIiIi+lhaj9nZvXs3du3ahUKFCmlML1myJB48eKCzwoiIiIh0Qeuenfj4eI0eHbWoqCiYm5vrpCgiIiIiXdE67NStWxcrV65U7qtUKqSmpmLGjBn47LPPdFocERER0cfSejfWjBkz0KhRI5w5cwaJiYkYMWIErl69iqioKBw9ejQ7aiQiIiL6YFr37JQvXx63bt1CnTp10KpVK8THx6NNmzY4f/48ihcvrtWyFixYgIoVK8LW1ha2trbw9vbGX3/9pcx/8+YNAgICkC9fPlhbW6Nt27aIiIjQWEZYWBj8/PyQJ08eODk5Yfjw4UhOTtZ2tYiIiMhAad2zAwB2dnb49ttvP/rJCxUqhGnTpqFkyZIQEaxYsQKtWrXC+fPnUa5cOQQGBmL79u3YsGED7OzsMGDAALRp00bpQUpJSYGfnx9cXFxw7NgxPH36FF26dIGpqSmmTJny0fURERFR7vdBYSc6OhpLlizB9evXAQAeHh7o1q0bHBwctFpOixYtNO5///33WLBgAU6cOIFChQphyZIlWLNmDRo2bAgAWLZsGcqWLYsTJ06gZs2a2L17N65du4a9e/fC2dkZnp6emDx5MkaOHIkJEybAzMwsw+dNSEhAQkKCcj82NlaruomIiCj30Ho31uHDh+Hm5oa5c+ciOjoa0dHRmDt3Ltzd3XH48OEPLiQlJQXr1q1DfHw8vL29cfbsWSQlJaFx48ZKmzJlyqBIkSI4fvw4AOD48eOoUKECnJ2dlTY+Pj6IjY3F1atXM32uqVOnws7OTrkVLlz4g+smIiKinE3rsBMQEIAvv/wSoaGh2Lx5MzZv3ox79+6hY8eOCAgI0LqAy5cvw9raGubm5ujbty+2bNkCDw8PhIeHw8zMDPb29hrtnZ2dER4eDgAIDw/XCDrq+ep5mQkKCkJMTIxye/jwodZ1ExERUe6g9W6sO3fuYOPGjTA2NlamGRsbY+jQoRqHpGdV6dKlceHCBcTExGDjxo3w9/fHoUOHtF6ONszNzXlOICIiok+E1j07VapUUcbqpHX9+nVUqlRJ6wLMzMxQokQJeHl5YerUqahUqRJ++uknuLi4IDExES9evNBoHxERARcXFwCAi4tLuqOz1PfVbYiIiOjTlqWenUuXLin/HzRoEAYPHow7d+6gZs2aAIATJ04gODgY06ZN++iCUlNTkZCQAC8vL5iammLfvn1o27YtAODmzZsICwuDt7c3AMDb2xvff/89IiMj4eTkBADYs2cPbG1t4eHh8dG1EBERUe6XpbDj6ekJlUoFEVGmjRgxIl27//u//8OXX36Z5ScPCgqCr68vihQpgpcvX2LNmjU4ePAgdu3aBTs7O/To0QNDhw6Fg4MDbG1tMXDgQHh7eyshq2nTpvDw8EDnzp0xY8YMhIeHY8yYMQgICOBuKiIiIgKQxbATGhqaLU8eGRmJLl264OnTp7Czs0PFihWxa9cuNGnSBAAwZ84cGBkZoW3btkhISICPjw/mz5+vPN7Y2BghISHo168fvL29YWVlBX9/f0yaNClb6iUiIqLcJ0thp2jRotny5EuWLHnvfAsLCwQHByM4ODjTNkWLFsWOHTt0XRoREREZiA86qeCTJ0/w999/IzIyEqmpqRrzBg0apJPCiIiIiHRB67CzfPly9OnTB2ZmZsiXLx9UKpUyT6VSMewQERFRjqJ12Bk7dizGjRuHoKAgGBlpfeQ6ERER0X9K67Ty6tUrdOzYkUGHiIiIcgWtE0uPHj2wYcOG7KiFiIiISOe03o01depUNG/eHDt37kSFChVgamqqMX/27Nk6K46IiIjoY31Q2Nm1axdKly4NAOkGKBMRERHlJFqHnVmzZmHp0qXo2rVrNpRDREREpFtaj9kxNzdH7dq1s6MWIiIiIp3TOuwMHjwY8+bNy45aiIiIiHRO691Yp06dwv79+xESEoJy5cqlG6C8efNmnRVHRERE9LG0Djv29vZo06ZNdtRCREREpHNah51ly5ZlRx1ERERE2YKnQSYiIiKDpnXPjru7+3vPp3Pv3r2PKoiIiIhIl7QOO0OGDNG4n5SUhPPnz2Pnzp0YPny4ruoiIiIi0gmtw87gwYMznB4cHIwzZ858dEFEREREuqSzMTu+vr7YtGmTrhZHREREpBM6CzsbN26Eg4ODrhZHREREpBNa78aqXLmyxgBlEUF4eDj++ecfzJ8/X6fFEREREX0srcPOF198oXHfyMgIjo6OaNCgAcqUKaOruoiIiIh0QuuwM378+Oyog4iIiChb8KSCREREZNCy3LNjZGT03pMJAoBKpUJycvJHF0VERESkK1kOO1u2bMl03vHjxzF37lykpqbqpCgiIiIiXcly2GnVqlW6aTdv3sSoUaOwbds2dOrUCZMmTdJpcUREREQf64PG7Dx58gS9evVChQoVkJycjAsXLmDFihUoWrSorusjIiIi+ihahZ2YmBiMHDkSJUqUwNWrV7Fv3z5s27YN5cuXz676iIiIiD5KlndjzZgxA9OnT4eLiwvWrl2b4W4tIiIiopwmy2Fn1KhRsLS0RIkSJbBixQqsWLEiw3abN2/WWXFEREREHyvLYadLly7/eug5ERERUU6T5bCzfPnybCyDiIiIKHvwDMpERERk0Bh2iIiIyKAx7BAREZFBY9ghIiIig8awQ0RERAaNYYeIiIgMGsMOERERGTS9hp2pU6eiWrVqsLGxgZOTE7744gvcvHlTo82bN28QEBCAfPnywdraGm3btkVERIRGm7CwMPj5+SFPnjxwcnLC8OHDkZyc/F+uChEREeVQeg07hw4dQkBAAE6cOIE9e/YgKSkJTZs2RXx8vNImMDAQ27Ztw4YNG3Do0CE8efIEbdq0UeanpKTAz88PiYmJOHbsGFasWIHly5dj3Lhx+lglIiIiymGyfAbl7LBz506N+8uXL4eTkxPOnj2LevXqISYmBkuWLMGaNWvQsGFDAMCyZctQtmxZnDhxAjVr1sTu3btx7do17N27F87OzvD09MTkyZMxcuRITJgwAWZmZvpYNSIiIsohctSYnZiYGACAg4MDAODs2bNISkpC48aNlTZlypRBkSJFcPz4cQDA8ePHUaFCBTg7OyttfHx8EBsbi6tXr2b4PAkJCYiNjdW4ERERkWHKMWEnNTUVQ4YMQe3atVG+fHkAQHh4OMzMzGBvb6/R1tnZGeHh4UqbtEFHPV89LyNTp06FnZ2dcitcuLCO14aIiIhyihwTdgICAnDlyhWsW7cu258rKCgIMTExyu3hw4fZ/pxERESkH3ods6M2YMAAhISE4PDhwyhUqJAy3cXFBYmJiXjx4oVG705ERARcXFyUNqdOndJYnvpoLXWbd5mbm8Pc3FzHa0FEREQ5kV57dkQEAwYMwJYtW7B//364u7trzPfy8oKpqSn27dunTLt58ybCwsLg7e0NAPD29sbly5cRGRmptNmzZw9sbW3h4eHx36wIERER5Vh67dkJCAjAmjVr8Mcff8DGxkYZY2NnZwdLS0vY2dmhR48eGDp0KBwcHGBra4uBAwfC29sbNWvWBAA0bdoUHh4e6Ny5M2bMmIHw8HCMGTMGAQEB7L0hIiIi/YadBQsWAAAaNGigMX3ZsmXo2rUrAGDOnDkwMjJC27ZtkZCQAB8fH8yfP19pa2xsjJCQEPTr1w/e3t6wsrKCv78/Jk2a9F+tBhEREeVgeg07IvKvbSwsLBAcHIzg4OBM2xQtWhQ7duzQZWlERERkIHLM0VhERERE2YFhh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUHTa9g5fPgwWrRoAVdXV6hUKmzdulVjvohg3LhxKFCgACwtLdG4cWPcvn1bo01UVBQ6deoEW1tb2Nvbo0ePHoiLi/sP14KIiIhyMr2Gnfj4eFSqVAnBwcEZzp8xYwbmzp2LhQsX4uTJk7CysoKPjw/evHmjtOnUqROuXr2KPXv2ICQkBIcPH0bv3r3/q1UgIiKiHM5En0/u6+sLX1/fDOeJCH788UeMGTMGrVq1AgCsXLkSzs7O2Lp1Kzp27Ijr169j586dOH36NKpWrQoAmDdvHpo1a4aZM2fC1dX1P1sXIiIiyply7Jid0NBQhIeHo3Hjxso0Ozs71KhRA8ePHwcAHD9+HPb29krQAYDGjRvDyMgIJ0+ezHTZCQkJiI2N1bgRERGRYcqxYSc8PBwA4OzsrDHd2dlZmRceHg4nJyeN+SYmJnBwcFDaZGTq1Kmws7NTboULF9Zx9URERJRT5Niwk52CgoIQExOj3B4+fKjvkoiIiCib5Niw4+LiAgCIiIjQmB4REaHMc3FxQWRkpMb85ORkREVFKW0yYm5uDltbW40bERERGaYcG3bc3d3h4uKCffv2KdNiY2Nx8uRJeHt7AwC8vb3x4sULnD17Vmmzf/9+pKamokaNGv95zURERJTz6PVorLi4ONy5c0e5HxoaigsXLsDBwQFFihTBkCFD8N1336FkyZJwd3fH2LFj4erqii+++AIAULZsWXz++efo1asXFi5ciKSkJAwYMAAdO3bkkVhEREQEQM9h58yZM/jss8+U+0OHDgUA+Pv7Y/ny5RgxYgTi4+PRu3dvvHjxAnXq1MHOnTthYWGhPOa3337DgAED0KhRIxgZGaFt27aYO3fuf74uRERElDPpNew0aNAAIpLpfJVKhUmTJmHSpEmZtnFwcMCaNWuyozwiIiIyADl2zA4RERGRLjDsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHsEBERkUFj2CEiIiKDxrBDREREBo1hh4iIiAwaww4REREZNIYdIiIiMmgGE3aCg4Ph5uYGCwsL1KhRA6dOndJ3SURERJQDGETYWb9+PYYOHYrx48fj3LlzqFSpEnx8fBAZGanv0oiIiEjPDCLszJ49G7169UK3bt3g4eGBhQsXIk+ePFi6dKm+SyMiIiI9M9F3AR8rMTERZ8+eRVBQkDLNyMgIjRs3xvHjxzN8TEJCAhISEpT7MTExAIDY2Fid15ea8Erny/wvaPu34HrmbFzP9HLrOgKfxnryPZuxT2U9tV2uiLy/oeRyjx8/FgBy7NgxjenDhw+X6tWrZ/iY8ePHCwDeeOONN954480Abg8fPnxvVsj1PTsfIigoCEOHDlXup6amIioqCvny5YNKpdJjZVkXGxuLwoUL4+HDh7C1tdV3OdmG62lYuJ6G41NYR4DrmdOJCF6+fAlXV9f3tsv1YSd//vwwNjZGRESExvSIiAi4uLhk+Bhzc3OYm5trTLO3t8+uErOVra1trnpjfiiup2HhehqOT2EdAa5nTmZnZ/evbXL9AGUzMzN4eXlh3759yrTU1FTs27cP3t7eeqyMiIiIcoJc37MDAEOHDoW/vz+qVq2K6tWr48cff0R8fDy6deum79KIiIhIzwwi7Hz55Zf4559/MG7cOISHh8PT0xM7d+6Es7OzvkvLNubm5hg/fny63XGGhutpWLiehuNTWEeA62koVCL/drwWERERUe6V68fsEBEREb0Pww4REREZNIYdIiIiMmgMO0RERGTQGHaIiIjIoDHs0CclLi5O3yVQFqSmpuq7BCIyIAw79MlYtWoVOnfujMePH+u7FK18SmeHOHz4MEQERkZGn9R6M9xRbpIbP5sMO58IbkzfXi8tPDwcY8aMyTWBJzU1Vbk4bVRUlJ6ryV4HDhxAr169MGbMGIgIVCpVrtyoais1NRVGRm83xbt27cKdO3f0XJHuzZw5E7///ru+y8hWn8I2Vv15TElJ0bifG9adYecTod6Yrl69GpcuXQKQO9P5xxg2bBi6du2KsLAwjBo1Ck+fPtV3Se+V9ktw5syZmDZtGi5fvqznqrJPpUqV0KJFCxw8eBDjxo37JAKPuhcLAEaNGoXAwED8/vvvePXqlZ4r052lS5dizpw5KFasmL5LyTZpP6tnz57NNT+mtKH+PO7btw8DBgzAl19+iWHDhiE2NjZX9MQy7HwiRARxcXHo168fNm/eDABKj8GnICkpCQDQtGlTVKxYEUePHsWYMWMQHh6u58oyp954jhgxAtOnT4eXlxccHBw02uT0DUxWpaamwsHBAWPGjEHt2rWxZ88egw486l/C6s/gjBkzsHjxYixbtgwDBw5Enjx59Fmezpw6dQqXLl3C5MmTUbVqVYN7HQHNwBoUFISBAwdi9+7dBhVYgbfv1S1btqBly5awtraGh4cH9u/fD09PT8TFxeX87xOhT0JKSoqIiMybN08qV64sN27c0HNF/721a9dKhQoVpF27dlKuXDmxs7MTf39/efTokb5Ly9TatWulUKFCcvHiRWVafHy8xuuXmpqqj9J0Tv0ejY6OluHDh0uNGjVkzJgxyvoZynq+efNG435MTIw0a9ZMgoODReR/66n+e+RWZ86cEXNzczE3N5effvpJ3+Xo3Lvvx0mTJkn+/Pll37598uLFCz1VpVtp34MRERHi5eWlvJYPHjyQggULSs+ePTUek1M/p+zZMVDyzi8o9S+P6tWr49WrV8ruEPW+V0N38+ZNDBkyBAEBAVi5ciWuXLmCESNG4ObNm/j2229zbA9PeHg4SpQogYoVK+L27duYM2cOPD090axZM/Tr1w+A4fTQqd+j9vb2GDVqFOrWrWtwPTw9e/bE6NGj002/evUq4uPjAfzv9TQyMsLr16/x5MmT/7TGj6V+jby8vDB//nxYWlpi//79uH37tp4r053Xr18rr5OI4PHjxwgJCcG8efPQsGFD2NnZKfNyozlz5uDAgQMwMjJSeiHj4uIQFRUFf39/PHnyBLVr14afnx9+/fVXAMAff/yBxMTEHLs9YtgxQOovBgDYsmULduzYocyrXr06PvvsM4wdOxbx8fEwNjbWV5nZSkQ0NjSvX79GamoqatasCUtLSwBvu5ybNWuGTZs2Ydy4cXj06JG+ygWgOcgvJiYGAGBjY4Nnz56hQ4cOaNmyJc6cOYPOnTtjxIgR2LRpkzL+KrdSv0a3bt3Cnj17cPbsWTx9+hQODg4GF3iSk5PRokULTJs2TbkPvN3FWqRIEdy7dw+vX7/WeMzVq1cxceLEHBvGM/Lq1StlF0737t0xbdo0nDx5EosXL8b9+/f1W5wO9OjRA+vWrVPuq1QqqFQqPHr0KN3uR5VKhYSEhBw/PjCtZ8+e4cCBA2jdujWOHj2q/AjJmzcvihcvjpCQEHh7e8PPzw/BwcEAgNDQUGzYsAFHjx7VZ+nvp58OJcouabsQV69eLW3atBFTU1Pp2bOnLFu2TERErl69KnXr1pUtW7aISO7vLn+fHTt2yOrVq+X06dNSunRp2bZtm4iIJCcnK21Kly4tLi4u0qdPH0lKStJLnWlfg5kzZ8qECRMkLCxMXr9+LVOnTpVOnTrJkiVL5N69eyIicvr0aalWrZrcvXtXL/Xqgvq9umnTJnFzc5PixYtLxYoV5YsvvpBLly6JiMizZ89k2LBhUrt2bRk6dGiO7SL/N+/WvWTJEmncuLHExcWJiMiyZctEpVLJzJkzJTo6WkREXrx4Ic2bN5dWrVrlms/orFmz5PPPP5d69epJu3bt5OXLlyIismDBAilYsKCMHDlS7t+/r+cqP1xKSopMmTJFEhMTRUSUf+/fvy9OTk4yZ84cERGN7cjJkyflhx9+UF7X3ODatWvSpUsXyZcvnxw5ckRERGJjY8XX11dUKpV07NhRo/3w4cPFy8tLnjx5oo9ys4Rhx4Ck3aCOHj1a6tSpI9euXZMjR45I69atpXz58lK9enX57bffpGTJktKrVy89Vpv9Tp06JcbGxvL7779LYmKi1K9fX6pWrSqhoaFKm6ioKGnTpo2MHz8+R4zdGT58uDg6OsrKlSvl4cOHynR1OEtJSZGXL19KixYtpEmTJrnmSzAze/bskbx588rPP/8sIiK//vqrWFtbS/Xq1eXMmTMi8jbw9OvXTxo3biyRkZH6LFcnUlJSZP78+VKlShVp166dEnjmzJkjJiYm0rhxY2nUqJF4e3tLhQoVlC/UnP5aBwUFiZOTkwQHB8u2bdvExsZG6tSpoxF4ihQpIn379pWnT5/quVrtvRtYFy1aJOPGjZOYmBgREZk8ebKYmJjIH3/8obR58+aN+Pj4SJcuXXJ8UB8xYoT0799fuX/9+nXp1KmT5MuXTw4dOiQiImFhYeLm5iZ169aV+fPny5YtW6R///5iZ2enMa4wJ2LYMUAnT56UJk2ayIkTJ5RpL1++lCdPnsjXX38tHTp0EAsLC1GpVLJr1y49Vpp9Ll26JBs2bJAxY8Yo06Kjo6VkyZLi5eUla9eulaNHj8rIkSPFy8srR3yJrly5UgoUKKD0aoiIxMXFyYMHD0Tk7cZ2wYIF4uPjI56enrnmSzCttIONY2Nj5csvv5SxY8eKiMjTp0+laNGi0qxZM6lXr55Uq1ZNLl++LCIiz58/l4iICL3V/TEyen1ev34tS5culWrVqkmbNm2UwLNz506ZPHmy9OnTR3744Qelh0BfPY5ZdfPmTalYsaLs3btXRES2b98utra2smDBAo1206ZNk1atWuX4L/6MvFtzr169xNPTU6ZPny5xcXESExMj/fv3F5VKJd27d5fu3btLgwYNpHz58spnNaeud2pqqmzbtk0uXLigMf3q1atK4Nm/f7+IiNy9e1eaN28uHh4e4uHhIZ9//nmODzoiDDsGZ+XKldKqVSvx9fWVN2/eSEpKSrqN7a1bt2TVqlVSqFAhGTVqlIjk3A/hh3j58qU4OTmJSqWSrl27asyLiYkRHx8fKVu2rLi6ukqxYsWUHgR9mzlzpjRv3lxE3r5Gc+fOlZIlS0q1atUkMDBQRESmT58uw4YNyzVfgiL/+7JPu+tQ/Wv/4MGDcvToUYmKipKKFStK7969ReTtUYMqlUpKlCghZ8+e/e+L1pG0n719+/bJvn37lPVJG3hat26tBJ53P69p/2451bFjx6RIkSIiIrJt2zaxtraWhQsXisjb3R+//vqr0jY3Hl136tQp5f9TpkyRLVu2SEpKigwcOFC8vLxkxowZ8vr1axF5O3ygZcuW0q5dO/nmm29y1WdVRGTXrl0a282MAk98fLw8f/5cnj9/Lq9evdJXqVph2DEw3333nbi6uoqLi4vcunVLRDI/lHXVqlVia2srYWFh/3md2e3ixYtSvnx5qVixojJGIO36h4aGypUrV3JEb4G6rmnTpknJkiWlZ8+eUq5cOaXX47vvvpMSJUrI48ePNTaYueFLUO3+/fsya9YsERH5/fffpVKlSkr3v8jbQ+zr1aun7N7YsWOH1KlTR3r16qWMU8rNhg8fLnZ2duLu7i6WlpayePFiERFJSEiQpUuXSvXq1TV2aeUW6m3Ls2fP5LPPPpNvv/1WrK2t5ZdfflHanDt3Tj7//HOlpzk1NTVXBZ2wsDAxNjaWPn36yDfffCM2NjZKj2NycrL0799fvLy8ZPr06RIbGysi6U8vkBM/q5n1CG/atElUKpXyw0NEM/AcPnz4vypRpxh2crHM3qy//PKLFCtWTHr06CF37txJN1+9oQkLC5NKlSql67rMbTLbcF66dEkKFCggzZo1k+fPn4tIztjl874ahg0bJm3btpVffvlFbt++LSJvfzV7eXnl6i/9UaNGiYeHh3Tq1ElMTU2VwfJq8+fPl/z58yvrOGrUKBk4cKBGIMpN0r4nr1+/Lh4eHnL69Gm5cOGCTJkyRYyMjGT27Nki8jbwLF++XNzc3GT06NH6KvmDqNfzxYsX0rZtWzE1NZWhQ4cq81+/fi3NmjXLVYOs35Wamir79+8XU1NTsbGxkZs3b4rI/wJNcnKyBAQESLVq1WT69Onp3rM5Odg9efJETp8+LSIi69atk8WLF0tqaqps3bpVrK2tpUePHkrbq1evSpcuXUSlUsnx48f1VfIHY9jJpdJuOHbv3i1bt26VFStWKNN+/vln8fT0lEGDBmX6JTlt2jRRqVTy+PHjbK83u6g3JCdOnJBFixbJ5MmTNdbn4sWL4uzsLH5+fkrg0ae0r9vixYulV69e0qdPH1m9erUyPW23cHx8vDRv3lx8fHxy7ZeFWuvWrUWlUkm7du2UaepfvEePHpUGDRpImTJlxNfXV/LkySNXrlzRV6k6M3XqVBk2bJgMGzZMmZaamiqzZ88WlUqlHL3z5s0b2b59e47sAcjIrFmzpHPnztKkSRNZt26dxMfHy4MHD6RixYpSr149GTZsmPz444/pxqzkpvdw2loPHjwoKpVKzM3NNQbxJiQkiMjb9/GAAQOkcOHCsmrVqv+81g/x8uVLady4sXz55ZfKd8HSpUtF5O26b9myJV3guXTpkvTu3VsJfLkJw04uN2LECHF3d5eaNWuKm5ubeHl5KV8SP/74o1SpUkWGDBmi7NJKa/v27XLu3Ln/umSdSXvosqOjo9SuXVuqVq0qjo6OsnXrVmWXwMWLF6VQoUJSp04diYqK0mfJihEjRkjBggWla9euMmDAADExMZF58+Yp82NjY+Wnn34SX19fqVSpUq78slB78+aNJCYmir+/v/j6+kqNGjVk8uTJ6c4y+8cff8jIkSOlV69ecvXqVT1VqzsJCQnSr18/UalUylgsNXXgMTU1lUmTJmnMy+mB59tvvxUHBwfp2bOntG7dWuzt7aVnz57y9OlTuX37tgQGBkqFChWkWbNmGqdzyC1jVkQ0P2e3bt2S2NhYiY6Oll27dom1tXWGR7KmpqbKvHnzcvzrl9bu3bulVKlSolKpZMKECRrz0gaetLu01AEvt2HYycUWLFggjo6OSmBZs2aNqFQq2b17t9Jmzpw5UrBgQeUXpKE5cuSIODo6Kr9IoqKiRKVSSYECBWTNmjUSHx8vIiJnz56V0qVL62V80rsbhxUrVoi7u7ucPHlSRP63j1ylUsn333+vtBs7dqwEBATkyi8Lkcy77wcPHixVqlRJF3jUQTQ3fVmkldH6RkZGytixY5VTILzbbuLEiVKnTp0cvasjradPn8rAgQM1xm2sXbtWKlasKAMGDBCRt69fQkKCxjrlpvdu2qAzZswYadq0qezevVuSk5MlMTFRtmzZIlZWVtK3b1+lXd++fZVzeInk/Pewur7IyEgpVaqUuLm5ib+/f7rdUykpKbJ161ZRqVTK65tbMezkIu9uEAMDA2XixIki8nZ/q52dnXKo57uDP3P6h+9DJCYmyty5c5XDy0NDQ6Vo0aIyePBg8ff3F3t7e1m/fr1y5M+7gwb/C4MHD5aFCxcqu6Zev34t06ZNk7lz54qISEhIiNjZ2cncuXOVruS01xFSv+a57fVT133w4EH55ptvpGvXrhqBOzAwUKpVqyaTJk2S58+fy5gxY8TLy0vevHmTa77400r7BZmQkKCxKzIqKkoCAwPF2NhYNm/eLCKan+XccnTSunXrRKVSSZEiRdJ9Ka5atUosLCwyHP+X09crM+rzBm3ZskWePXumMW/z5s2SJ08eqV27ttSqVUtKlCiRqwKdyNsfipGRkRIeHi47d+6UatWqyVdffZXutU1NTZWQkBC5fv26nirVDYadXCo1NVU+++wzmTBhghw9elSsra2VoJOSkiKjR4+W+fPnazwmt31hZibtxvP06dNy8eJFefnypdSrV0+5KN3Dhw/FyspKzMzMZOPGjfoqVRo1aiTly5eXVatWKb1Mjx8/ljt37sjDhw/Fw8NDOUrpxIkTYm5uLiqVKsNDdXObzZs3i52dnXTq1EnGjBkjKpVK/u///k8JncOGDZPy5ctLyZIlxdnZOVcOehTRDDpz5sxRzhM0YsQIZXpsbKwMGTJETE1NZevWremWkRte49DQUOnUqZOoVCrlxHnq3asiIu7u7um2ObnVsWPHpGjRonLs2DEReTuOLjQ0VP7880+5du2aiLztLfb395dhw4Ypf4fcso2Njo6WIkWKKL2NIiJbt26VatWqSadOnZT1HjdunCxZskRfZeoUw04ucOzYMWWXx8CBA5U338qVK8XT01NMTU2VQ1lF/ncV5XHjxuml3uzyvi+ECxcuiKenp/KFef36denRo4f07t1bL79I0n4BdujQQcqWLSsrV67UOLT44MGDUqFCBeUU65cvX5ZevXrJtm3bct2vxHfdv39fSpcurYxDevnypdjb20tgYKDG32bnzp2yevXqDI8azG1GjRolrq6uMmHCBFm8eLEYGxtLr169lIHxsbGxMnToUFGpVMoZaXOb0NBQadmypeTLl0/Onz+vTP/nn3/Ezc0t1wzO/TcnT56USpUqydmzZ+Xs2bMSGBgoJUqUEHd3dylZsqTGCVvVctNn9uXLl1KqVCmZOXOmxvQ//vhDateuLTVr1pQWLVqISqVSjtbK7Uz0fW0uypz8/6vp9u3bFxUrVgQArF+/HmfOnAEAVK5cGQUKFICRkREKFCgAALh79y4GDRqEf/75B2PHjtVb7bom//8ikH///Td27doFY2NjuLm5oWvXrgCAJ0+e4MaNG0hOTsbLly+xdu1aREZGYsuWLXq52Kn6gpUqlQrr16+Hv78/vv/+ewBAu3btYGlpCRMTE1y5cgV79uxBvXr1MGrUKFhaWsLPzw8qlQrJyckwMcmdH9E3b97A1tYWAwYMwP3791G7dm106NABs2fPBgCcPn0a1apVg4+Pj54r1Y0//vgDmzdvxoYNG1CrVi3s3r0bJiYmWLlyJSIiIrB8+XLkzZsX48aNQ9GiRVGrVi19l5wl6m2NkZERqlSpAjc3NwQHB6NPnz5o2LAhBg0aBGdnZ2zfvh02Njbo2LGjnivWnqS5wKz6AspWVlaIj4/HkCFDlIvvTpkyBe7u7ujatSvCwsJQo0YNjeXk5M+qet3UFxu2trbGZ599hgcPHgB4e6FkS0tLtGzZEnny5MGhQ4cQFhaGy5cvo1y5cvosXXf0mbTo/dQ9Gbt27RIXFxcxMTGR3377TWPeoUOHpFmzZuLq6ioFCxYUT09PqVWrVq7rVs2KTZs2SZ48ecTPz0+8vb3F2tpa2rZtq/yi8vHxEWNjYylfvrzY29vr7cy7aXugVq5cKStXrhQRkc6dO0uZMmU0enhGjBghKpVKihcvLpUrV87xp5XPqitXroibm5ts3bpVihUrJr1791Zep/Pnz0vDhg01LouR26R9fVJSUuT3339Xxlrt2LFD8ubNK7/++qscOXJEzMzMpGfPnvLPP/9oLCOn9wSMGTNGihcvLiVLlhRbW1uZNWuWsj15+PChtGvXTlQqlXTu3FkWL16snEE4p69XWml7GcPDw+XFixfK7uZTp07J0qVLZefOncoYrMTERKlSpYqsX79eL/V+jH379km5cuWkVatWMnv2bKlSpYo0bNhQ4uPjMzzCypC+O0S4GytHU29Q//rrL6lXr554eHhkOGI+LCxM+WAePHhQeZPmpo3OvwkLCxN3d3flC+XVq1dy5MgRcXV1ldatWyvtFi1aJMuXL1dOyPdfS7vxvHLlilSuXFkqVaqkHKnRuXNnKV26tKxatUoJNmfPnpX9+/fn2tdN/T5VX3RWfSX2r7/+WqytrTVeH5G3Az9r1aol4eHh/3mtupA26KiPJouLi5PQ0FCJjo6WGjVqyJQpU0TkbShwc3MTlUolw4cP10u9H2Ly5Mni7Owshw4dkvj4eBk0aJCoVCoZM2aM8j69f/++tG/fXpycnJRdxfo4COBDpf2sTp06VWrWrCmVK1eWxo0bK+fqUq/rmzdvJCIiQnx9faVatWq5Kgioz1h9+vRpCQoKkoEDB0rDhg3F09NTVCqVeHh4SK1ataRHjx4SEBBgEOe3ygjDTg60detW5aRN3377rfTv319evXolf/31V6Yj5t+Vmz6MWXH58mVxc3NTBgeqHTx4UGxtbWXNmjV6qixj6jMh16pVSxwcHKRYsWKyadMmEflf4Fm9erVypJhabn3d1OfjKFGihJibm8uqVatk1apVUq1aNWnZsqWEhITIvn37JDAwMFdcITkzab8gV61aJb1791YuRyLy9oKYJUuWVAZ4RkZGSu/eveX8+fO55rW9fv26+Pn5SUhIiIi83R7Z29uLv7+/GBsby9ixY5WegIcPHyo9y+pLKOQGaV/H0aNHi7Ozs6xYsUJCQkKkYsWKUrx4ceXcZG/evJHJkydLgwYNxNvbO9f0mr+vdzg5OVlOnTollStXlmnTpsm8efOkQ4cOUrt27Vx/1FVmGHZymLi4OGnSpIlYW1tL165dxdzcXOOLQT1ivnPnzvL333+LiMjnn38ua9eu1VfJ/4knT56IjY2NLF++XGN6dHS0lCtXTn788Uc9VZbesmXLlN1oUVFR8vTpU2natKlUrVpVORLH399f8ubNK3/99Zeeq/04KSkp8vz5c6ldu7ZyiYvJkyeLiYmJBAcHy/z58+XLL78US0tLqVChgtSpUyfXXp4k7Rfk+fPnxc/PTwoWLCjDhg1TegLCw8PFxsZG+vTpI7t375amTZtKvXr1ctUpBCIjI2XhwoUSFxcnhw8floIFC8rPP/8sIiLdunUTlUolgwcPVtbp0aNHUqdOHSlZsqTG0Vk5kbrXUW3v3r1SpUoVOXLkiIiI/Pnnn2JnZyfFihUTZ2dnJfCcP39efvrpp1zT+6p+bfbt2yf9+vWTL7/8UsaPH69xSpIbN26InZ2dEsxTU1Nz5UlLs4phJweKj48XFxcXMTc3V74c0+5TVY+Y9/T0lEqVKombm1uO38hkVWYXCVSfgbdJkyayd+9ejXn16tVTrjOUE8a6fPvtt1KnTh2NK84/evRIatSooYxjEXm7qyC3vm7qv/Pr16/l1atXMnr0aI2zU8+ePVtMTEzkxx9/lIiICHnw4IE8f/483VmTc6MhQ4ZI1apVpVOnTlKrVi2xsbGRoUOHKpdl2bJli9jb20vZsmWldu3auWYc1u3bt+XRo0cau6IGDBggX3/9tTIeZ+TIkdKwYUOpV6+eRnB7/Phxjr+gcN++faVp06YaY/kOHz6snMH6r7/+EkdHRwkODpabN2+Kq6urlCpVKl2PVW4IrCJv34e2trbSo0cP+eGHH8TCwkJatmwpT58+Vd6LNWrUSHedOkPFsJMDRURESPXq1aVmzZri5OSknDo/7Rfj4cOH5aeffpIxY8bk2jPspvXuSbv27t0rY8eOld69e8uhQ4fk5cuXcunSJWnUqJE0aNBA5s+fL8eOHZOhQ4dK3rx5c8Shy+oNyKRJk6Rq1arKF4T6ddu/f7/kyZNH6tatq+wiEMk9G893bd26VXx8fMTDw0PKlCmTbtfUnDlzxMzMTEaPHp1rL+j5rpCQEHFwcJCzZ88qQXbChAni4eEhQ4cOVU4jEBkZKbdu3VLa5PTP5siRI6VMmTKSP39+qV+/vtKT89lnn0mnTp1E5O37uFWrVrJ9+3blcbnpvbtv3z4pXry4fPXVVxqHUz958kSSkpLEx8dHgoKCROTtD84GDRqIpaWl+Pr6ikjOD6tpPXr0SKPHOzY2VpycnGTQoEEa7apXr66cm8zQMezkABl1Hb5+/VqePXsmvr6+4ujomG6syrvXeMpNG513rVixQvLly6eEuj///FPMzMzE19dXKlasKIUKFZJu3bpJeHi4XL58WXr37i12dnZSpkwZqVChgsb5PnKCS5cuibGxcbprzezcuVPatm0rDRs2lMaNG+eqwZzvOn36tNja2krfvn2la9euYmpqKoMHD9YYvyLy9mKzefPmTRdmc4t3P1dbtmyRIkWKpOvFGDVqlJiZmck333wjoaGhGvNy+q6BtWvXiouLi2zdulWWL18uw4cPFxMTE1m0aJHs3LlTVCqVtGjRQipWrCgVKlRQgltu+vJXvwZ///23FCtWTDp27CinTp1S5j969Ejc3NyUkyW+ePFCOnToICdPnszRr19GtaWmpsqDBw+kcuXKkpycLA8ePBBXV1eN61sdOHBARN5eP9FQx+i8i2FHz9K+WU+dOiWnT5/W6GZ9+PCh+Pr6iouLi1y4cEESEhKkY8eOMmrUKH2Umy2io6OlevXqUqZMGbly5Yr06NFD40ysv/76qzRo0EB69Ogh8fHxkpqaKs+ePZMHDx7kmAt7vmvZsmViamoqw4cPlzNnzsjdu3fFz89Pvv/+e7l27ZqoVCrZs2ePvsv8IHfu3JFx48bJ1KlTlWnz58+XQoUKyahRo9IFnpz6Gmnju+++k507d8rvv/8uBQoUUIK5evdyVFSUFChQQDw9PWX8+PESGxurz3Kz7MCBA9KzZ09lN7DI216AuXPnSp48eWTdunWyYcMG6dSpkwwdOlQJOrnpx5V6G6v+9/Dhw1KsWDFp3769nDlzRmlXv359KVOmjKxYsULq1asntWrVSvfYnCgsLEw2bNggIm+Da8+ePeXBgwdSokQJWbVqVbpTP1y/fl3q168vly9fzlWB9WMx7OhR2jfa+85p8ejRI2nZsqUYGRlJlSpVpESJErl2rEdahw8fVn7xv3jxQmrWrCnFihWT6tWrpwsCv/zyixQsWFBj45TTbdy4UZycnKRQoUJSsGBBqVy5srx+/Vru378vJUuWzJVHJMXExEjVqlUlf/78Mnr0aI15P//8sxQsWFC+/fZbZfyKSO7qAVBL++W2bt06MTU1VcZuVK9eXapWraox/uj27dvSuXNnGThwoLi6uuaKX8tPnz6V4sWLi42NjXz33Xca854/fy5ffPGFDBw4UEQ0xwzm9F1yab179fKHDx+KiMjVq1eVwKPu4Tl//rw0btxYKlWqJH5+fso2NicHncTEROnYsaPUqlVLAgMDRaVSyS+//CIiIj169BAbGxtp2bKlxmOCgoKkevXqyi7XTwXDTg6QlXNaiIgsX75cFi5cmOvH6KSmpsr58+eVdVT/8n/x4oX4+fmJSqVSrmKedkNTvHhxGTlypF5q/lCPHj2S48ePy+HDh5V1GTVqlJQpU0aePn2q5+o+zLlz56RkyZJSu3btdIM3FyxYIBYWFjJx4sRc+/5Ma+PGjbJkyRJZtGiRMu3OnTtSrlw5KVeunKxevVr+/PNP8fHxkS+//FJERPLly6fR65WTXbx4UYoXLy5VqlSRc+fOaczr0aOHfP7553qq7OOlDdnqMUn58uWTOnXqyNatW+Xu3btSrFgxadeuncYPj8ePHyuPzQ3vYfW5nVQqlfTr10+Zvnv3bqlRo4Y0adJEVq9eLSEhITJo0CCxtbXNlT+0PhbDjp5l5ZwWaa+grJabupEzs2DBAjExMZHx48crPTxRUVHy2WefSZEiRTTG4iQmJoq3t7dy0czc6MqVK9K5c+d01xXKjS5evCienp7Su3fvdCchW7x4sXLIbm728OFDsba2FpVKla7nIzIyUlq0aCGlS5cWNzc3adCggbx69UqSkpKkUqVKGhdYzOkuXrwolSpVki5duijvy9jYWKlVq5b06tVLv8V9oLQ/kt4dkzRs2DAxMjKSFStWyN27d6V48eLy5ZdfytGjRzNdRk6WmJionCSwSZMmGtcn27p1q3Tp0kXs7OykUqVK8tlnn32SQUeEYec/9+4HKCvntBgyZIhB7LZSS05OVv4OixYtEpVKJdOmTZPIyEgRedvDU6tWLSlcuLD8/PPPsnXrVgkKChIbGxu5ceOGPkv/YElJSXLu3Dn55ptvDOYMpefOnZMqVapIz549lTEsuVlGX26HDx8WT09PqVGjhnJ0XdofGg8fPtToCRg7dqwUKVIk3SDlnO7cuXPi4eEhLi4u0rx5c2nTpo1UrlxZ2X2VG3dFimQ+Jumnn34SCwsLOXr0qJw7d07y5MmTqy+c/ObNG3n69Kn4+fnJZ599plyiRu3hw4cSFxeX7iSmnxKGnf9Q2o2ktue0yK0bm4yo12Xnzp3Kry4LCwuZNGmScoXoFy9eSMOGDUWlUkmjRo0kICDAIH6RGFJoFXn7JVm9enXp2LFjrhinkpm0QWfr1q2yYMECWbx4sdy8eVMOHz4sJUuWlKZNmypt3n0dr169Kl26dBFHR8d0u4Nyi8uXL4u7u7vUrVtXFixYoEzPre/Z941JioqKkpYtW0pAQICISK46w/X7qA+EaNSokaxYsUJE3u42z609dLrEsPMfmD9/vsYGcMSIER90TgtDCjw7duwQExMTmT17tsydO1eGDBkiKpVKxo8frwSe6OhoqVmzplSrVi1XH6Zt6E6dOiX169c3iAGP33zzjeTPn1/q1KkjVlZWUqtWLZk1a5YcPnxYihcvrjGGJe3n8fHjx7J8+XLlMi+51fnz56VGjRrSq1cvvV1fTpf+bUySj4+PxjRDCDz37t2T1q1bS/ny5aVatWpia2srJ06c0HdZesewk83u3bsnhQoVkl69esmdO3dk8+bNBn9Oi/dJTk6WpKQkad26tXTp0kVj3rx580SlUsmkSZOUXVoxMTEaR/ZQzqTujczNNmzYIAUKFJAzZ85IamqqREdHS8+ePaVBgwaycOFCOXLkiBQqVEiqV6+e4eMN5TNqKL11aoY4JunfPHr0SJYsWSITJ07Mtbv+dU0lIgLKVhcuXEDPnj1Rp04dJCQkoFSpUggMDAQAvHz5EsuXL8eoUaOwdOlSGBsbY+vWrXB2dsb06dNhYmKClJQUGBsb63ktPo6IQKVSISIiAs7OzmjatClKlSqFn3/+GcnJyTAyMoKRkRH69u2LtWvXYtCgQQgMDISDg4O+S6dPxIwZM7B582YcOXIExsbGMDIyQkREBPr374/4+Hjs3LkT+/fvx08//YQtW7bAyMhI3yVnm9OnT2P48OFYu3YtChQooO9yPtr58+fx9ddfIyoqClWrVoWZmRlCQ0Nx4sQJmJmZKdsnMlyG+2nNQTw9PbFo0SIcPXoU69evR3x8vDLPxsYGnTp1QtOmTXH06FG0a9cOS5cuxaxZs2BiYoLk5ORcH3QAQKVSYe3atShYsCBev36NWrVq4ffff0dYWBhMTEyQmpoKAChSpAjs7e0RHByMlJQUPVdNnwL17z0TExO8efMGiYmJMDIyQnJyMpydnREUFITdu3fj8uXLaNiwIf744w8YGRkp71lDVK1aNezcudMggg4AVK5cGevXr4elpSViYmLQpEkTnDt3DmZmZkhKSmLQ+QQw7PxHqlSpgqVLl8LOzg5btmzB+fPnlXkODg7Ily8fbt++DQAwMzNT5pmYmPznteqS+ovk2bNn2LdvH2bOnAlLS0t8/fXX8PT0xFdffYWHDx8q6xkdHY25c+ciNDQUjo6O+iydPhHqL7rPP/8cV65cwcyZMwH877OXkpKCcuXKIU+ePBqPM+SeHQCwsLDQdwk6Vb58eWzevBmJiYk4d+4c7ty5AwAwNTXVc2X0XzDsT2sOU6FCBfzxxx9ISUnBjz/+iAsXLgB4uyvr+vXrKFy4sH4LzAYqlQpnzpxBmzZtcOvWLTRr1gwAUKJECXzzzTewtraGp6cnOnXqBF9fXwQHB6NkyZKws7PTc+X0qfHw8MCSJUvw/fff45tvvsGxY8dw/fp1TJw4EXnz5oW7u7u+S6SP5OnpiQULFuDixYsYO3Ysbty4oe+S6D/CMTt6oN5/HB0djapVq8Lc3Bx3797FyZMnYWpqanD7j1etWoWffvoJt2/fxtWrV1GoUCFlXlhYGNauXYtLly4hT548GDJkCMqVK6fHaulTt3nzZgwYMAAqlQp58uSBk5MTDh48CFNTU6Smphp8j86nwNDGJNG/Y9jRkytXrqB169awsLDA8OHD0alTJxgbGyM5OTnX77p6V0pKCjZu3IixY8fC2dkZW7duRb58+fRdFlGmwsPDERERgcTERHh5eSljeAzts/kpe/PmjcHtqqPMMezo0enTp7F48WIsXLgQKpXKIH41qnuloqOjYW5ujoSEBOTNmxcpKSlYv349fv75Zzg4OGDVqlXImzcvkpKSuM+ccjxD+GwSfcoYdvRMHQ4MYWOqXpft27dj7ty5ePLkCcqWLYsuXbqgefPmSE5Oxrp167BgwQLkz58fS5cuZQ8PERFlu9z97WoAVCoVRCTXBx3g7br8+eef6NChAxo0aIARI0bAysoKnTt3xqZNm2BiYoKOHTsiICAAd+7cQf/+/Q368F0iIsoZ2LNDOnPnzh189dVX6N69O/r164fIyEh4eXnBxsYGDx8+xNKlS9G+fXskJydj8+bNqF69Otzc3PRdNhERGbjc351AeqXOyomJiXBwcIC3tzc6dOiAR48eoW7dumjWrBm2bt2KypUro3v37lizZg1MTEzQoUMHBh0iIvpPsGeHPph6jM7evXuxfft2DBo0CPnz54eNjQ0CAwPx8OFDLF++HNbW1ujTpw+2bNkCS0tLXLp0Cba2tgZ1eD0REeVc7NmhD6ZSqbB582a0bNkSDg4OeP78OWxsbJCUlIQLFy6gUKFCsLa2BvD2LKVTpkzB+fPnYWdnx6BDRET/GZ40gj7YrVu3MGzYMMyaNQv9+vVTppuamqJatWrYtGkTSpcujevXr2Pz5s345ptveGFPIiL6zzHs0AcLCwuDqampcgkI4H+7tr766ivExcXhhx9+gIODA7Zv387T7RMRkV4w7NAHi4uLw+vXr5X7qampyu6pV69eoUuXLvjhhx+QlJQEe3t7PVVJRESfOo7ZoQ9WqVIlPHv2DIsWLQLw9irQ6rCzceNGbN++HZaWlgw6RESkV+zZoQ/m7u6On3/+GX379kVSUhK6dOkCY2NjLF++HMuXL8fx48cN4mSJRESUu/HQc/ooqamp2LRpE/r06QMrKytYWFjA2NgYa9euReXKlfVdHhEREcMO6caTJ0/w4MEDqFQquLu7w9nZWd8lERERAWDYISIiIgPHARVERERk0Bh2iIiIyKAx7BAREZFBY9ghIiIig8awQ0RERAaNYYeIiIgMGsMOERERGTSGHSIiIjJoDDtERERk0Bh2iIiIyKAx7BAREZFB+38lAeybWYKlhgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data distribution\n",
    "x = np.arange(NB_CLASSES)\n",
    "y = []\n",
    "for i in range(NB_CLASSES):\n",
    "    y.append(dataset.targets.count(i))\n",
    "\n",
    "plt.title(\"Data distribution accross classes of the dataset\")\n",
    "plt.bar(x, y)\n",
    "plt.xticks(x, CLASSES, rotation=45)\n",
    "plt.ylabel(\"Number of instances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Préprocessing\n",
    "Pour entrainer le modèle, on ne travaille pas directement sur l'image mais sur une représentation de celle sous forme d'une matrice (Tensor). Les variables `train_transform` et `test_transform` permettent de réaliser ces transformations en plus de les normaliser.\n",
    "\n",
    "### Expension du dataset\n",
    "\n",
    "Afin de d'améliorer au mieux la qualité de notre modèle, nous avons augmenter artificilement la taille du dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Campagne de selection d'un modèle\n",
    "\n",
    "### Procédure globale\n",
    "\n",
    "Le workflow est le suivant : on sépare les données d'entrainements en un set d'entrainement et un set de validation. Ce set de validation permet d'evaluer les performances de nos modèles afin de pouvoir trouver le plus approprié. Une fois le modèle bien définit, on le réentrainera une nouvelle fois mais sur l'intégralité des données cette fois ci.\n",
    "\n",
    "Afin de trouver une architecture adaptée à notre objectif, nous nous sommes inspiré de modèles de classifcation d'images existant. Dans notre cas, on s'est innspiré de VGG11. En partant de sa structure de base, nous avons essayé de l'adapter au mieux afin d'obtenir les meilleures performances possibles.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # Declare all the layers for feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            \n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Dropout(0.3)\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Declare all the layers for classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            # nn.Linear(512, 256),\n",
    "            # nn.ReLU(),\n",
    "            # nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes),\n",
    "            nn.Softmax(dim=1),\n",
    "            #nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the feature extractor in the input\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Squeeze the three spatial dimentions in one\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Classifiy the image\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques de régularisation\n",
    "\n",
    "- Régularisation L1 / L2 (weight decay)\n",
    "- Dropout\n",
    "\n",
    "### Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCNN(num_classes=NB_CLASSES)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=0.01)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "if device == 'xpu':\n",
    "    model, optimizer = ipex.optimize(model, optimizer=optimizer, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader):\n",
    "    ########## Training ##########\n",
    "    model.train()\n",
    "\n",
    "    train_n_corrects = 0\n",
    "    train_n_total = 0\n",
    "    train_losses = []\n",
    "\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "            # L1_term = torch.tensor(0., requires_grad=True)\n",
    "            # for name, weights in model.named_parameters():\n",
    "            #     if 'bias' not in name:\n",
    "            #         weights_sum = torch.sum(torch.abs(weights))\n",
    "            #     L1_term = L1_term + weights_sum\n",
    "\n",
    "            # L1_term = L1_term / nweights\n",
    "            # loss = loss + L1_REG * L1_term\n",
    "\n",
    "\n",
    "        train_n_corrects += (predicted == target).sum().item()\n",
    "        train_n_total += target.numel()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_epoch_acc = train_n_corrects / train_n_total\n",
    "    train_epoch_loss = np.mean(train_losses).__float__()\n",
    "\n",
    "    ########## Print results ##########\n",
    "    print(f\"Train accuracy: {train_epoch_acc}\")\n",
    "    print(f\"Train loss: {train_epoch_loss}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    return model, train_epoch_acc, train_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, val_values, val_predictions):\n",
    "    ########## Testing ##########\n",
    "        model.eval()\n",
    "        test_n_corrects = 0\n",
    "        test_n_total = 0\n",
    "        test_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "\n",
    "                val_values.append(target)\n",
    "                val_predictions.append(predicted)\n",
    "                test_n_corrects += (predicted == target).sum().item()\n",
    "                test_n_total += target.numel()\n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "        test_epoch_acc = test_n_corrects / test_n_total\n",
    "        test_epoch_loss = np.mean(test_losses).__float__()\n",
    "\n",
    "        #### Print results ####\n",
    "        print(f\"Test accuracy: {test_n_corrects / test_n_total}\")\n",
    "        print(f\"Test loss: {np.mean(test_losses)}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "        return test_epoch_acc, test_epoch_loss, val_values, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, full_dataset):\n",
    "\n",
    "    if full_dataset:\n",
    "        dataset.transform = train_transform\n",
    "        sampler = RandomSampler(dataset)\n",
    "        train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "\n",
    "    elif not full_dataset:\n",
    "        train_dataset, test_dataset = random_split(dataset, [0.9, 0.1])\n",
    "        train_dataset.dataset.transform = train_transform\n",
    "        test_dataset.dataset.transform = test_transform\n",
    "        train_sampler = RandomSampler(train_dataset)\n",
    "        test_sampler = RandomSampler(test_dataset)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "\n",
    "\n",
    "    train_graph_acc = []\n",
    "    train_graph_loss = []\n",
    "    test_graph_acc = []\n",
    "    test_graph_loss = []\n",
    "\n",
    "    val_values = []\n",
    "    val_predictions = []\n",
    "\n",
    "\n",
    "    # nweights = 0\n",
    "    # for name,weights in model.named_parameters():\n",
    "    #     if 'bias' not in name:\n",
    "    #         nweights = nweights + weights.numel()\n",
    "        \n",
    "\n",
    "    for epoch in range(NB_EPOCHS):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        model, train_epoch_acc, train_epoch_loss = train_epoch(model, train_loader)\n",
    "\n",
    "        if not full_dataset:\n",
    "            val_values = []\n",
    "            val_predictions = []\n",
    "\n",
    "            test_epoch_acc, test_epoch_loss, val_values, val_predictions = test_model(model, test_loader, val_values, val_predictions)\n",
    "            \n",
    "            train_graph_acc.append(train_epoch_acc)\n",
    "            train_graph_loss.append(train_epoch_loss)\n",
    "            test_graph_acc.append(test_epoch_acc)\n",
    "            test_graph_loss.append(test_epoch_loss)\n",
    "    \n",
    "    \n",
    "\n",
    "    ########## Visualise results ##########\n",
    "    x = np.arange(1, NB_EPOCHS + 1)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel('Number of epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.plot(x, train_graph_acc, label='Train Accuracy', color='tab:blue')\n",
    "    ax1.plot(x, test_graph_acc, label='Test Accuracy', color='tab:cyan')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.plot(x, train_graph_loss, label='Train Loss', color='tab:green')\n",
    "    ax2.plot(x, test_graph_loss, label='Test Loss', color='tab:olive')\n",
    "    ax2.tick_params(axis='y')\n",
    "    fig.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    cm = confusion_matrix(torch.cat(val_values).cpu(), torch.cat(val_predictions).cpu())\n",
    "    cm_display = ConfusionMatrixDisplay(cm, display_labels=CLASSES)\n",
    "    cm_display.plot(xticks_rotation='vertical')\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 86/87 [00:16<00:00,  5.22it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 512])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m########## Save the model ##########\u001b[39;00m\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(trained_model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[39], line 35\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, full_dataset)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NB_EPOCHS):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m     model, train_epoch_acc, train_epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m full_dataset:\n\u001b[1;32m     38\u001b[0m         val_values \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[37], line 14\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 14\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m     16\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[35], line 75\u001b[0m, in \u001b[0;36mCustomCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Classifiy the image\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2507\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2495\u001b[0m         batch_norm,\n\u001b[1;32m   2496\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2504\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2505\u001b[0m     )\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m-> 2507\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2510\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2511\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2475\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2473\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 512])"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, full_dataset=False)\n",
    "\n",
    "########## Save the model ##########\n",
    "torch.save(trained_model.state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Kaggle\n",
    "Cette partie est consacrée à reprendre le modèle entrainé et à prédire une classe sur de nouvelles images non connues et non labellées. Ces prédictions sont exportées dans un fichier .csv avec les identifiants de chaque image afin de pouvoir être évaluées dans le cadre d'une compétiton Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WasteSubmissionDataset(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.image_list = os.listdir(main_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.image_list[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        img_id = os.path.splitext(os.path.basename(img_loc))[0]\n",
    "        return tensor_image, img_id\n",
    "\n",
    "test_dataset = WasteSubmissionDataset(main_dir=TEST_DATA, transform=test_transform)\n",
    "submission_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on redéfinit une classe personnalisée pour transformer nos images en Tensors. Les transformations appliquées sont identiques à celles du set de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     ID    Label\n",
      "0  69d436c1-429f-4c15-b780-bf599f779ae2  battery\n",
      "1  02b8a2d3-7444-4e50-9f46-d1fbc7f1c5a4  organic\n",
      "2  aff9561d-77cc-4d15-a77f-9b3477acb968    paper\n",
      "3  772a7ee5-97c0-4b4f-82c1-4e36486fb488  battery\n",
      "4  69e14833-a7be-45e7-8c35-7504245e72ab  textile\n"
     ]
    }
   ],
   "source": [
    "def generate_submission(model, submission_loader):\n",
    "    model.eval()\n",
    "\n",
    "    images_id = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (img, tuple_img_id) in enumerate(submission_loader):\n",
    "            img = img.to(device)\n",
    "            output = model(img)\n",
    "            prob = torch.nn.functional.softmax(output, dim=1)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            for i, img_id  in enumerate(tuple_img_id):\n",
    "                images_id.append(img_id)\n",
    "                predictions.append(CLASSES[predicted[i]])\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame({'ID': images_id, 'Label': predictions})\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(df.head())\n",
    "\n",
    "generate_submission(trained_model, submission_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
